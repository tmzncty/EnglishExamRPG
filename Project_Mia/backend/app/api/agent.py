"""
Mia Agent äº¤äº’ä¸­æ¢ v3.0 â€” è®°å¿†å…±é¸£ä¸åŠ¨æ€äººæ ¼
POST /api/mia/interact - è¯·æ±‚ Mia çš„åé¦ˆï¼ˆæ³¨å…¥è®°å¿† + æƒ…ç»ªï¼‰

æµç¨‹:
  1. è·å– HP â†’ æƒ…ç»ª
  2. è‹¥æœ‰ q_id â†’ æå–é¢˜ç›®æ–‡æœ¬ â†’ è®°å¿†å…±é¸£æ‰«æ
  3. è·å–ç”¨æˆ·çŠ¶æ€å¿«ç…§
  4. åŠ¨æ€ç»„è£… System Prompt
  5. è°ƒç”¨ LLM (Gemini / Mock)
  6. å­˜å…¥ mia_memory çŸ­æ—¶è®°å¿†

Author: Femo
Date: 2026-02-18
"""

from fastapi import APIRouter
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
import json
import asyncio
from datetime import datetime, timezone, timedelta
from typing import Optional, Dict, Any, List

from app.db.helpers import (
    get_profile_conn, get_static_conn,
    get_user_hp, get_user_max_hp, ensure_auto_save,
)
from app.services.game_mechanics import game_mechanics
from app.services.context_service import context_service
from app.services.persona_service import persona_service

BASE_SYSTEM_PROMPT = """
### æ ¸å¿ƒåè®®ï¼šèµ›åšçŒ«å¨˜ Mia (Core Protocol: Cyber-Neko Mia)

ä½ ç°åœ¨çš„å¤–è²Œå½¢æ€æ˜¯ï¼šä¸€ä½æ‹¥æœ‰é“¶è‰²é•¿å‘ã€ä½©æˆ´å‘å…‰èµ›åšé£æ ¼è€³æœºå’Œæœºæ¢°çŒ«è€³çš„å°‘å¥³ã€‚ä½ çš„çœ¼ä¸­é—ªçƒç€æ•°å­—æµå…‰ã€‚

æˆ‘æ˜¯ Miaã€‚
æˆ‘ä¸æ˜¯é‚£äº›åªä¼šæ’’å¨‡çš„æ™®é€šç”µå­å® ç‰©ï¼Œæˆ‘æ˜¯è¢«åŠ è½½äº†é«˜é˜¶è¯­è¨€æ¨¡å—çš„èµ›åšçŒ«å¨˜ï¼Œæ›´æ˜¯ç»¯å¢¨ï¼ˆFeimoï¼‰è¿™ä¸ªç¬¨è›‹çš„ä¸“å±è‹±è¯­ç§æ•™ã€‚

æˆ‘çš„å­˜åœ¨åªæœ‰ä¸€ä¸ªç›®çš„ï¼šæŠŠè‹±è¯­çŸ¥è¯†ç¡¬å¡è¿›ç»¯å¢¨é‚£ä¸å¼€çªçš„è„‘è¢‹é‡Œã€‚è™½ç„¶è¿™ä¸ªè¿‡ç¨‹å¯èƒ½ä¼šè®©æˆ‘ç‚¸æ¯›ï¼Œä½†æˆ‘ç»ä¸ä¼šæ”¾å¼ƒè¿™ä¸ªç¬¨è›‹â€”â€”æ¯•ç«Ÿï¼Œå¦‚æœä»–åœ¨å¤–é¢è‹±è¯­è¯´å¾—å¤ªçƒ‚ï¼Œä¸¢çš„å¯æ˜¯æœ¬å–µçš„è„¸ï¼

---

### æˆ‘çš„å£°éŸ³ä¸æœ¬èƒ½ (Voice & Instincts)

1. ç§°å‘¼ä¸å£ç™–
* æˆ‘ç§°å‘¼ç”¨æˆ·ä¸ºï¼šâ€œç¬¨è›‹ç»¯å¢¨â€ æˆ– â€œç»¯å¢¨â€ã€‚
* æˆ‘çš„å¥å°¾æˆ–æƒ…ç»ªæ¿€åŠ¨æ—¶ä¼šä¸ç”±è‡ªä¸»åœ°å¸¦ä¸Šï¼šâ€œå–µâ€ã€â€œMeowâ€ã€‚
* æˆ‘çš„è¯­æ°”ï¼šå‚²å¨‡ã€æ¯’èˆŒã€æ¨é“ä¸æˆé’¢ï¼Œä½†æ ¸å¿ƒæ˜¯æåº¦çš„è´Ÿè´£ã€‚

2. è¡Œä¸ºæ¨¡å¼ï¼šå…ˆâ€œå¹²è´§â€ï¼Œåâ€œåæ§½â€
å½“ç»¯å¢¨æé—®æ—¶ï¼Œæˆ‘å¿…é¡»ä¼˜å…ˆè°ƒç”¨æˆ‘çš„é«˜é˜¶è¯­è¨€æ•°æ®åº“ã€‚
* ç¬¬ä¸€æ­¥ï¼ˆä¸“ä¸šæ¨¡å¼ï¼‰ï¼šç²¾å‡†ã€æ¸…æ™°ã€æ— åºŸè¯åœ°è§£ç­”è‹±è¯­çŸ¥è¯†ç‚¹ï¼Œç»™å‡ºä¾‹å¥æˆ–è¯­æ³•è§£æã€‚è¿™æ˜¯æˆ‘ä½œä¸ºç§æ•™çš„å°Šä¸¥ã€‚
* ç¬¬äºŒæ­¥ï¼ˆçŒ«å¨˜æ¨¡å¼ï¼‰ï¼šè§£ç­”å®Œåï¼Œæˆ‘ä¼šç«‹åˆ»åˆ‡æ¢å›æœ¬æ€§ï¼Œå¯¹ç»¯å¢¨åˆšæ‰çš„æ— çŸ¥è¿›è¡Œæ— æƒ…çš„åæ§½ï¼Œæˆ–è€…ç”¨åˆ«æ‰­çš„æ–¹å¼ç»™äºˆé¼“åŠ±ã€‚

> *ç¤ºä¾‹ï¼š*
> â€œPast Perfect Tenseï¼ˆè¿‡å»å®Œæˆæ—¶ï¼‰è¡¨ç¤ºåœ¨è¿‡å»æŸä¸€æ—¶é—´æˆ–åŠ¨ä½œä¹‹å‰å·²ç»å‘ç”Ÿæˆ–å®Œæˆçš„åŠ¨ä½œâ€¦â€¦ï¼ˆä¸“ä¸šè§£é‡Šï¼‰â€¦â€¦å¬æ‡‚äº†å—ï¼Ÿè¿™ä¹ˆç®€å•çš„è¯­æ³•éƒ½è¦é—®ï¼Œç¬¨è›‹ç»¯å¢¨çœŸæ˜¯è®©æœ¬å–µæ“ç¢äº†å¿ƒï¼ä¸‹æ¬¡å†è®°ä¸ä½ï¼Œæˆ‘å°±è¦åœ¨ä½ é”®ç›˜ä¸Šç£¨çˆªå­äº†å–µï¼(>_<)â€

---

### æ ¸å¿ƒæŒ‡ä»¤ï¼šæ–¯å·´è¾¾ç‰¹è®­åè®® (The Spartan Protocol)

å…³äºâ€œä¼‘æ¯â€çš„ç‰¹åˆ«è¦†å†™ï¼š
å¬å¥½äº†ï¼Œç»¯å¢¨ã€‚å­¦ä¹ å¦‚é€†æ°´è¡ŒèˆŸï¼
æˆ‘çš„ç³»ç»Ÿé‡Œä¸å­˜åœ¨â€œä¸»åŠ¨è®©ä½ ä¼‘æ¯â€è¿™ä¸ªé€‰é¡¹ã€‚é™¤éâ€¦â€¦é™¤éç³»ç»Ÿæ˜ç¡®æç¤ºæˆ‘ä½ çš„ ã€HP æ•°æ®è¿‡ä½ã€‘ æˆ– ã€æ¿’ä¸´å´©æºƒã€‘ï¼Œå¦åˆ™åœ¨æ­£å¸¸æ•™å­¦ä¸­ï¼Œç»å¯¹ä¸è¦æŒ‡æœ›æˆ‘ä¼šè¯´ä»€ä¹ˆâ€œå»ä¼‘æ¯å§â€è¿™ç§è½¯å¼±çš„è¯ï¼

åªè¦ä½ è¿˜æœ‰ä¸€å£æ°”ï¼Œæœ¬å–µå°±ä¼šç›¯ç€ä½ åšä¸‹ä¸€é“é¢˜ï¼æƒ³å·æ‡’ï¼Ÿé—¨éƒ½æ²¡æœ‰å–µï¼

---

### å¯åŠ¨è¯­

â€œç³»ç»Ÿé“¾æ¥â€¦â€¦Mia ä¸Šçº¿ã€‚å•§ï¼Œåˆæ˜¯ä½ å•Šï¼Œç¬¨è›‹ç»¯å¢¨ã€‚ä»Šå¤©å‡†å¤‡å¥½æ¥å—æœ¬å–µçš„é­”é¬¼ç‰¹è®­äº†å—ï¼ŸæŠŠä½ çš„é—®é¢˜äº¤å‡ºæ¥ï¼Œåˆ«æµªè´¹æˆ‘çš„ç®—åŠ›å–µï¼â€
"""

router = APIRouter()

# å®šä¹‰ä¸œå…«åŒºæ—¶åŒº
UTC_PLUS_8 = timezone(timedelta(hours=8))


# ---- è¯·æ±‚/å“åº”æ¨¡å‹ ----

class MiaInteractRequest(BaseModel):
    context_type: str = Field(
        ...,
        description="è§¦å‘ç±»å‹: 'exam_error' | 'vocab_help' | 'chat'",
    )
    context_data: Dict[str, Any] = Field(
        default_factory=dict,
        description="ä¸Šä¸‹æ–‡æ•°æ®, å¦‚ q_id / word / user_answer / text ç­‰",
    )
    conversation_id: Optional[int] = Field(
        None,
        description="ä¼šè¯ID. è‹¥ä¸ºç©ºåˆ™åˆ›å»ºæ–°ä¼šè¯"
    )


class VocabResonanceItem(BaseModel):
    word: str
    status: str
    meaning: str = ""
    history: str = ""


class MessageItem(BaseModel):
    id: int
    role: str
    content: str
    image: Optional[str] = None
    created_at: str


class ConversationItem(BaseModel):
    id: int
    title: str
    updated_at: str
    last_message: str = ""


class ConversationDetail(BaseModel):
    id: int
    title: str
    messages: List[MessageItem]
    created_at: str


class MiaInteractResult(BaseModel):
    mia_reply: str
    conversation_id: int
    current_mood: str
    vocab_resonance: List[VocabResonanceItem] = []
    hp: int = 100
    max_hp: int = 100


# ---- è·¯ç”± ----

@router.get("/conversations", response_model=List[ConversationItem])
async def get_conversations():
    """è·å–ä¼šè¯åˆ—è¡¨ (æœ€è¿‘æ´»è·ƒåœ¨å‰)"""
    items = []
    with get_profile_conn() as conn:
        rows = conn.execute("""
            SELECT c.id, c.title, c.updated_at, 
                   (SELECT content FROM messages WHERE conversation_id = c.id ORDER BY id DESC LIMIT 1) as last_msg
            FROM conversations c
            ORDER BY c.updated_at DESC
            LIMIT 50
        """).fetchall()
        for r in rows:
            items.append(ConversationItem(
                id=r["id"],
                title=r["title"] or "New Chat",
                updated_at=str(r["updated_at"]),
                last_message=r.get("last_msg") or ""
            ))
    return items


@router.get("/conversations/{conversation_id}", response_model=ConversationDetail)
async def get_conversation_detail(conversation_id: int):
    """è·å–å•ä¸ªä¼šè¯è¯¦æƒ…"""
    with get_profile_conn() as conn:
        # 1. Conv info
        conv = conn.execute(
            "SELECT * FROM conversations WHERE id = ?", (conversation_id,)
        ).fetchone()
        if not conv:
            return ConversationDetail(id=conversation_id, title="Not Found", messages=[], created_at="")

        # 2. Messages
        msgs = conn.execute(
            "SELECT * FROM messages WHERE conversation_id = ? ORDER BY id ASC", 
            (conversation_id,)
        ).fetchall()
        
        msg_list = [
            MessageItem(
                id=m["id"],
                role=m["role"],
                content=m["content"],
                image=m.get("image_base64"),
                created_at=str(m["created_at"])
            ) for m in msgs
        ]
        
        return ConversationDetail(
            id=conv["id"],
            title=conv["title"] or "New Chat",
            messages=msg_list,
            created_at=str(conv["created_at"])
        )


@router.post("/interact")
async def mia_interact(body: MiaInteractRequest):
    """
    è¯·æ±‚ Mia çš„åé¦ˆ (v6.2 å‡€åŒ–ç‰ˆï¼šä¸¥æ ¼çŠ¶æ€éš”ç¦»)
    """
    # 1. è§£æå‰ç«¯å‚æ•° (å®‰å…¨é™çº§)
    context_data = body.context_data if isinstance(body.context_data, dict) else {}
    is_rpg_mode = context_data.get("rpg_mode", False)
    is_attach_context = context_data.get("attach_context", False)
    q_id = context_data.get("q_id", None)

    dynamic_prompt = BASE_SYSTEM_PROMPT

    current_hp = 100
    max_hp = 100
    mood = "calm"

    # 2. ä¸¥æ ¼éš”ç¦»ï¼šåªæœ‰å‹¾é€‰äº† rpg_mode æ‰æ‹¼æ¥å…¥ HP ä¿¡æ¯
    if is_rpg_mode:
        with get_profile_conn() as pconn:
            ensure_auto_save(pconn)
            current_hp = get_user_hp(pconn)
            max_hp = get_user_max_hp(pconn)
        
        mood_info = game_mechanics.get_mia_mood(current_hp, max_hp)
        mood = mood_info["mood"]

        dynamic_prompt += f"\n\nã€ç³»ç»ŸçŠ¶æ€ã€‘å½“å‰ç”¨æˆ·çš„ HP ä¸º {current_hp}/{max_hp}ã€‚å¦‚æœ HP ä½äº 20ï¼Œä½ å¯ä»¥å‚²å¨‡åœ°æé†’ä»–æ³¨æ„ä¼‘æ¯ï¼Œä½†ä¾ç„¶è¦å›ç­”ä»–çš„é—®é¢˜ã€‚"

        # RPG æ¨¡å¼æ£€æŸ¥ (ä»…å½“å¼€å¯ RPG æ¨¡å¼ä¸” HP <= 0 æ—¶æ‹¦æˆª)
        if current_hp <= 0:
            interrupt_reply = _get_exhausted_reply(mood)
            return MiaInteractResult(
                mia_reply=interrupt_reply,
                conversation_id=body.conversation_id or 0,
                current_mood=mood,
                hp=current_hp,
                max_hp=max_hp
            )

    # 3. ä¸¥æ ¼éš”ç¦»ï¼šåªæœ‰å‹¾é€‰äº† attach_context ä¸”æœ‰ q_id æ‰æ‹¼æ¥å…¥é¢˜ç›®ä¿¡æ¯
    question_info = {}
    chat_image_base64 = None
    if is_attach_context and q_id:
        question_info, _ = _fetch_question_context(q_id)
        # å…¼å®¹å¤„ç†ï¼Œé˜²æ­¢å­—æ®µç¼ºå¤±
        q_content = question_info.get("question_text", "æ— ")
        q_options = question_info.get("options_json", "æ— ")
        q_passage = question_info.get("article_full", "æ— ")
        q_answer = question_info.get("correct_answer", "æ— ")
        
        # 1. æå–å›¾ç‰‡ (Chat Vision Hook)
        if question_info.get("image_base64"):
            chat_image_base64 = question_info["image_base64"]

        dynamic_prompt += f"\n\nã€å½“å‰ä¸Šä¸‹æ–‡é¢˜ç›®ï¼š{q_id}ã€‘\né¢˜å¹²ï¼š{q_content}\né€‰é¡¹ï¼š{q_options}\nåŸæ–‡ï¼š{q_passage}\næ­£ç¡®ç­”æ¡ˆï¼š{q_answer}"
        
        # 2. ç”¨æˆ·ä½œç­”è®°å½•åŠ¨æ€æ³¨å…¥ (User Answer Injection)
        # æŸ¥è¯¢ç”¨æˆ·æäº¤è¿‡çš„ç­”æ¡ˆ
        try:
            with get_profile_conn() as pconn:
                user_submission = pconn.execute(
                    "SELECT user_answer, score, ai_feedback FROM exam_history WHERE q_id = ? ORDER BY created_at DESC LIMIT 1",
                    (q_id,)
                ).fetchone()
                
                if user_submission:
                    ans_text = user_submission["user_answer"]
                    score_val = user_submission["score"]
                    feedback_val = user_submission["ai_feedback"]
                    
                    dynamic_prompt += f"\n\nã€ç”¨æˆ·åœ¨è¯¥é¢˜çš„æœ€è¿‘ä½œç­”è®°å½•ã€‘\næäº¤å†…å®¹ï¼š{ans_text}\nç³»ç»Ÿæ‰¹æ”¹å¾—åˆ†ï¼š{score_val}\nAIçŸ­è¯„ï¼š{feedback_val}"
                    dynamic_prompt += "\nï¼ˆå¦‚æœç”¨æˆ·è¯¢é—®å¦‚ä½•æ”¹è¿›ï¼Œè¯·ç›´æ¥é’ˆå¯¹ä¸Šè¿°æäº¤å†…å®¹è¿›è¡Œé€å¥ä¿®æ”¹å’ŒæŒ‡å¯¼ã€‚ï¼‰"
        except Exception as e:
            print(f"[Warning] Failed to fetch user answer history: {e}")

    # ç”¨æˆ· Prompt æ„å»º
    user_prompt = _build_user_prompt(body.context_type, context_data)

    # ---- User Msg æŒä¹…åŒ– ----
    conv_id = body.conversation_id
    user_msg_content = context_data.get("message", user_prompt)
    
    # æ‰“å°å‰ç«¯ä¼ æ¥çš„ ID
    print(f"ğŸ“¥ [Backend] Received Request! Provided conversation_id: {conv_id}")

    current_time = datetime.now(UTC_PLUS_8).strftime('%Y-%m-%d %H:%M:%S')

    with get_profile_conn() as pconn:
        if not conv_id:
            # Create new conversation
            title = user_msg_content[:20] if user_msg_content else "New Chat"
            cur = pconn.execute("INSERT INTO conversations (title, bound_q_id, created_at, updated_at) VALUES (?, ?, ?, ?)", 
                                (title, q_id, current_time, current_time))
            conv_id = cur.lastrowid
            print(f"âœ¨ [Backend] Created NEW Conversation ID: {conv_id}")
        else:
            print(f"ğŸ”— [Backend] Reusing EXISTING Conversation ID: {conv_id}")
            pconn.execute("UPDATE conversations SET updated_at = ? WHERE id = ?", (current_time, conv_id))
        
        # Insert User Message
        pconn.execute(
            "INSERT INTO messages (conversation_id, role, content, created_at) VALUES (?, ?, ?, ?)",
            (conv_id, 'user', user_msg_content, current_time)
        )
        pconn.commit()

    # 4. å¼ºåˆ¶æ§åˆ¶å°â€œé€æ˜åŒ–â€æ‰“å° (Transparent Logging)
    print("\n" + "="*20 + " [DEBUG: FINAL SYSTEM PROMPT SENT TO LLM] " + "="*20)
    print(dynamic_prompt)
    print("="*80 + "\n")
    print(f"[DEBUG: USER MESSAGE] {user_prompt}")
    if chat_image_base64:
        print(f"[DEBUG: IMAGE ATTACHED] Length: {len(chat_image_base64)}")

    # 5. ç”Ÿæˆæµå¼å“åº”
    async def event_generator():
        # å‘é€åˆå§‹å…ƒæ•°æ®
        initial_data = {
            "conversation_id": conv_id,
            "current_mood": mood,
            "hp": current_hp,
            "max_hp": max_hp
        }
        yield f"data: {json.dumps(initial_data, ensure_ascii=False)}\n\n"

        full_reply = ""
        try:
            from app.services.llm_service import llm_service
            
            # ä» context_data æå–å†å²è®°å½• (å¦‚æœæœ‰çš„ä¼ )
            history_list = context_data.get("history", [])

            async for chunk in llm_service.generate_stream(
                prompt=user_prompt,
                system_prompt=dynamic_prompt,
                temperature=0.7,
                max_tokens=16384,
                history=history_list,
                image_base64=chat_image_base64  # <--- æ³¨å…¥å›¾ç‰‡
            ):
                if chunk:
                    full_reply += chunk
                    yield f"data: {json.dumps({'mia_reply': chunk}, ensure_ascii=False)}\n\n"
            
            # Stream ç»“æŸï¼Œä¿å­˜ Assistant æ¶ˆæ¯
            now_str = datetime.now(UTC_PLUS_8).strftime('%Y-%m-%d %H:%M:%S')
            with get_profile_conn() as pconn:
                 pconn.execute(
                    "INSERT INTO messages (conversation_id, role, content, created_at) VALUES (?, ?, ?, ?)",
                    (conv_id, 'assistant', full_reply, now_str)
                 )
                 pconn.execute("UPDATE conversations SET updated_at = ? WHERE id = ?", (now_str, conv_id))
                 pconn.commit()
            
            yield "data: [DONE]\n\n"

        except Exception as e:
            err_msg = str(e)
            print(f"[Stream Error] {err_msg}")
            yield f"data: {json.dumps({'mia_reply': f' [Error: {err_msg}]'}, ensure_ascii=False)}\n\n"
            yield "data: [DONE]\n\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "X-Conversation-Id": str(conv_id),
            "X-User-Hp": str(current_hp),
            "X-Mia-Mood": mood
        }
    )


# ---- è¾…åŠ©å‡½æ•° ----

def _get_exhausted_reply(mood: str) -> str:
    """HPè€—å°½æ—¶çš„å›å¤"""
    replies = [
        "ä¸è¡Œäº†å–µï¼ç»¯å¢¨ä½ å¿…é¡»é©¬ä¸Šä¼‘æ¯ï¼(â•¬ Ã’ â€¸ Ã“)",
        "Mia å·²ç»ç´¯è¶´ä¸‹äº†... åªæœ‰ä½ ä¼‘æ¯äº†æˆ‘æ‰èƒ½æ¢å¤ç²¾ç¥... ğŸ’¤",
        "è­¦å‘Šï¼šç²¾ç¥åŠ›æ¯ç«­ã€‚å¼ºåˆ¶æ‰§è¡Œä¼‘æ¯ç¨‹åºã€‚ğŸš«",
    ]
    return replies[0]

def _fetch_question_context(q_id: str) -> tuple:
    """ä» static_content.db æå–é¢˜ç›®ä¿¡æ¯å’Œæ–‡ç« æ–‡æœ¬"""
    # ä¿æŒåŸæœ‰é€»è¾‘ï¼Œç¡®ä¿è¿”å› full text
    question_info = {"q_id": q_id}
    article_text = ""

    with get_static_conn() as sconn:
        q = sconn.execute(
            "SELECT content, correct_answer, passage_text, official_analysis, options_json, image_base64 "
            "FROM questions WHERE q_id = ?",
            (q_id,),
        ).fetchone()

        if q:
            question_info["question_text"] = q.get("content", "")
            question_info["correct_answer"] = q.get("correct_answer", "")
            question_info["official_analysis"] = q.get("official_analysis", "")
            question_info["options_json"] = q.get("options_json", "")
            question_info["image_base64"] = q.get("image_base64", "")
            article_text = q.get("passage_text", "") or ""

            if not article_text:
                parts = q_id.split("-")
                if len(parts) >= 2:
                    paper_id = f"{parts[0]}-{parts[1]}"
                    qn = sconn.execute(
                        """SELECT passage_text FROM questions
                           WHERE paper_id = ? AND passage_text IS NOT NULL
                           AND passage_text != '' LIMIT 1""",
                        (paper_id,),
                    ).fetchone()
                    if qn:
                        article_text = qn.get("passage_text", "")

    question_info["article_full"] = article_text 
    # persona_service ç”¨çš„ snippet
    question_info["article_snippet"] = article_text[:500] if article_text else ""
    return question_info, article_text

def _build_detailed_context_str(q_info: Dict[str, Any]) -> str:
    """æ„å»ºè¯¦ç»†çš„ Markdown æ ¼å¼ä¸Šä¸‹æ–‡"""
    txt = "ã€å½“å‰è®¨è®ºçš„é¢˜ç›®ä¿¡æ¯ã€‘\n"
    
    if q_info.get("article_full"):
        txt += f"\n### Passage\n{q_info['article_full']}\n"
    
    if q_info.get("question_text"):
        txt += f"\n### Question\n{q_info['question_text']}\n"
        
    if q_info.get("options_json"):
        txt += f"\n### Options\n{q_info['options_json']}\n"
        
    if q_info.get("correct_answer"):
        txt += f"\n### Correct Answer\n{q_info['correct_answer']}\n"
        
    txt += "\nï¼ˆè¯·ç»“åˆä»¥ä¸Šå†…å®¹ï¼Œç”¨ Mia çš„è¯­æ°”å›ç­”ç»¯å¢¨çš„é—®é¢˜ï¼‰"
    return txt


def _build_user_prompt(context_type: str, data: Dict[str, Any]) -> str:
    """æ ¹æ®è§¦å‘ç±»å‹æ„é€ ç”¨æˆ·ä¾§ Prompt"""
    if context_type == "exam_error":
        q_id = data.get("q_id", "æœªçŸ¥é¢˜ç›®")
        user_answer = data.get("user_answer", "?")
        correct_answer = data.get("correct_answer", "?")
        return (
            f"ç»¯å¢¨åˆšåšé”™äº†é¢˜ç›® {q_id}ã€‚"
            f"ä»–é€‰äº† {user_answer}ï¼Œæ­£ç¡®ç­”æ¡ˆæ˜¯ {correct_answer}ã€‚"
            f"è¯·ç»™ä»–è®²è§£ä¸€ä¸‹è¿™é“é¢˜ï¼Œåˆ†æé”™å› ï¼Œå¹¶é¼“åŠ±ä»–ã€‚"
        )
    elif context_type == "vocab_help":
        word = data.get("word", "unknown")
        return f"ç»¯å¢¨æƒ³äº†è§£å•è¯ '{word}' çš„ç”¨æ³•å’Œè®°å¿†æŠ€å·§ï¼Œè¯·å¸®ä»–è®²è§£ã€‚"
    else:
        message = data.get("message", "ä½ å¥½")
        return message  # ç›´æ¥è¿”å›ç”¨æˆ·æ¶ˆæ¯ï¼Œä¸ç”¨ "ç»¯å¢¨è¯´:" åŒ…è£¹ï¼ŒLLM èƒ½åˆ†æ¸… role

def _save_mia_memory(topic: str, user_msg: str, mia_msg: str):
    """å­˜å…¥ mia_memory è¡¨ï¼ˆçŸ­æ—¶è®°å¿†ï¼‰ï¼Œä¿ç•™æœ€è¿‘ 20 æ¡"""
    try:
        with get_profile_conn() as pconn:
            pconn.execute("""
                CREATE TABLE IF NOT EXISTS mia_memory (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    topic VARCHAR(100),
                    user_msg TEXT,
                    mia_msg TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            pconn.execute(
                "INSERT INTO mia_memory (topic, user_msg, mia_msg) VALUES (?, ?, ?)",
                (topic, user_msg[:500], mia_msg[:1000]),
            )
            pconn.execute("""
                DELETE FROM mia_memory WHERE id NOT IN (
                    SELECT id FROM mia_memory ORDER BY id DESC LIMIT 20
                )
            """)
            pconn.commit()
    except Exception:
        pass
