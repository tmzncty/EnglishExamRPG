"""
é¢„æ„å»º SQLite æ•°æ®åº“å¹¶è½¬æ¢ä¸º Base64
è¿™æ ·ç”¨æˆ·æ‰“å¼€ç½‘é¡µå°±èƒ½ç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€å¯¼å…¥
"""

import sqlite3
import json
import base64
from pathlib import Path


def create_database():
    """åˆ›å»ºå¹¶å¡«å…… SQLite æ•°æ®åº“"""
    
    # åˆ›å»ºå†…å­˜æ•°æ®åº“
    conn = sqlite3.connect(':memory:')
    cursor = conn.cursor()
    
    # åˆ›å»ºè¡¨ç»“æ„
    cursor.execute('''
        CREATE TABLE vocabulary (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            word TEXT UNIQUE NOT NULL,
            meaning TEXT NOT NULL,
            pos TEXT,
            frequency INTEGER DEFAULT 0,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    cursor.execute('''
        CREATE TABLE sentences (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            word_id INTEGER NOT NULL,
            sentence TEXT NOT NULL,
            translation TEXT,
            year INTEGER,
            question_number INTEGER,
            section_name TEXT,
            section_type TEXT,
            exam_type TEXT,
            question_range TEXT,
            question_label TEXT,
            source_label TEXT,
            question_text TEXT,
            FOREIGN KEY (word_id) REFERENCES vocabulary(id)
        )
    ''')
    
    cursor.execute('''
        CREATE TABLE learning_records (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            word_id INTEGER NOT NULL,
            sentence_id INTEGER NOT NULL,
            is_correct BOOLEAN,
            repetition INTEGER DEFAULT 0,
            easiness_factor REAL DEFAULT 2.5,
            interval INTEGER DEFAULT 0,
            next_review DATETIME,
            last_review DATETIME DEFAULT CURRENT_TIMESTAMP,
            consecutive_correct INTEGER DEFAULT 0,
            is_mistake BOOLEAN DEFAULT 0,
            FOREIGN KEY (word_id) REFERENCES vocabulary(id),
            FOREIGN KEY (sentence_id) REFERENCES sentences(id)
        )
    ''')
    
    cursor.execute('''
        CREATE TABLE explanations (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            word_id INTEGER NOT NULL,
            sentence_id INTEGER NOT NULL,
            explanation TEXT NOT NULL,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (word_id) REFERENCES vocabulary(id),
            FOREIGN KEY (sentence_id) REFERENCES sentences(id),
            UNIQUE(word_id, sentence_id)
        )
    ''')
    
    cursor.execute('''
        CREATE TABLE settings (
            key TEXT PRIMARY KEY,
            value TEXT NOT NULL
        )
    ''')
    
    cursor.execute("INSERT INTO settings (key, value) VALUES ('dailyGoal', '20')")
    
    # è¯»å–è¯æ±‡æ•°æ®
    vocab_file = Path(__file__).parent / 'data' / 'exam_vocabulary.json'
    print(f"ğŸ“– æ­£åœ¨è¯»å–è¯æ±‡æ–‡ä»¶: {vocab_file}")
    
    with open(vocab_file, 'r', encoding='utf-8') as f:
        vocabulary = json.load(f)
    
    print(f"ğŸ“š å…± {len(vocabulary)} ä¸ªå•è¯")
    
    # å¯¼å…¥æ•°æ®
    imported = 0
    skipped = 0
    
    for i, word_data in enumerate(vocabulary):
        try:
            # æ ¼å¼åŒ–é‡Šä¹‰
            if 'meanings' in word_data and word_data['meanings']:
                meaning = 'ï¼›'.join(word_data['meanings'])
            elif 'primary_meaning' in word_data:
                meaning = word_data['primary_meaning']
            else:
                meaning = 'å¾…è¡¥å……'
            
            pos = word_data.get('pos', '')
            frequency = word_data.get('frequency', len(word_data.get('sentences', [])))
            
            # æ’å…¥å•è¯
            try:
                cursor.execute(
                    'INSERT INTO vocabulary (word, meaning, pos, frequency) VALUES (?, ?, ?, ?)',
                    (word_data['word'], meaning, pos, frequency)
                )
                word_id = cursor.lastrowid
            except sqlite3.IntegrityError:
                # å•è¯å·²å­˜åœ¨ï¼Œè·å– ID
                cursor.execute('SELECT id FROM vocabulary WHERE word = ?', (word_data['word'],))
                word_id = cursor.fetchone()[0]
            
            # æ’å…¥ä¾‹å¥
            for sentence in word_data.get('sentences', []):
                try:
                    cursor.execute('''
                        INSERT INTO sentences (
                            word_id, sentence, translation, year, question_number,
                            section_name, section_type, exam_type, question_range,
                            question_label, source_label, question_text
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        word_id,
                        sentence['sentence'],
                        sentence.get('translation'),
                        sentence.get('year'),
                        sentence.get('question_number'),
                        sentence.get('section_name'),
                        sentence.get('section_type'),
                        sentence.get('exam_type'),
                        sentence.get('question_range'),
                        sentence.get('question_label'),
                        sentence.get('source_label'),
                        sentence.get('question_text')
                    ))
                except sqlite3.IntegrityError:
                    pass  # ä¾‹å¥å·²å­˜åœ¨
            
            imported += 1
            
            if (i + 1) % 500 == 0:
                print(f"â³ å·²å¤„ç† {i + 1}/{len(vocabulary)} ä¸ªå•è¯...")
                
        except Exception as e:
            print(f"âŒ å¯¼å…¥ {word_data.get('word', '?')} å¤±è´¥: {e}")
            skipped += 1
    
    conn.commit()
    
    print(f"\nâœ… å¯¼å…¥å®Œæˆï¼")
    print(f"   æˆåŠŸ: {imported} ä¸ªå•è¯")
    print(f"   è·³è¿‡: {skipped} ä¸ª")
    
    # ç»Ÿè®¡ä¿¡æ¯
    cursor.execute('SELECT COUNT(*) FROM vocabulary')
    vocab_count = cursor.fetchone()[0]
    cursor.execute('SELECT COUNT(*) FROM sentences')
    sentence_count = cursor.fetchone()[0]
    
    print(f"\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡:")
    print(f"   è¯æ±‡æ•°: {vocab_count}")
    print(f"   ä¾‹å¥æ•°: {sentence_count}")
    
    return conn


def export_to_base64(conn):
    """å°†æ•°æ®åº“å¯¼å‡ºä¸º Base64"""
    
    # å°†å†…å­˜æ•°æ®åº“ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    temp_file = Path(__file__).parent / 'vocab_prebuilt.db'
    backup = sqlite3.connect(str(temp_file))
    conn.backup(backup)
    backup.close()
    
    print(f"\nğŸ’¾ æ•°æ®åº“å·²ä¿å­˜: {temp_file}")
    print(f"   æ–‡ä»¶å¤§å°: {temp_file.stat().st_size / 1024 / 1024:.2f} MB")
    
    # è¯»å–å¹¶è½¬æ¢ä¸º Base64
    with open(temp_file, 'rb') as f:
        db_bytes = f.read()
    
    base64_data = base64.b64encode(db_bytes).decode('ascii')
    
    # ä¿å­˜ Base64 åˆ°æ–‡ä»¶
    base64_file = Path(__file__).parent / 'data' / 'vocab_prebuilt.txt'
    with open(base64_file, 'w', encoding='utf-8') as f:
        f.write(base64_data)
    
    print(f"ğŸ“¦ Base64 å·²ä¿å­˜: {base64_file}")
    print(f"   Base64 å¤§å°: {len(base64_data) / 1024 / 1024:.2f} MB")
    
    return base64_data, str(base64_file)


def main():
    print("ğŸš€ å¼€å§‹æ„å»ºé¢„å¡«å……æ•°æ®åº“...\n")
    
    # åˆ›å»ºå¹¶å¡«å……æ•°æ®åº“
    conn = create_database()
    
    # å¯¼å‡ºä¸º Base64
    base64_data, base64_file = export_to_base64(conn)
    
    conn.close()
    
    print(f"\nâœ¨ å®Œæˆï¼ç°åœ¨å¯ä»¥ä¿®æ”¹ index.html è‡ªåŠ¨åŠ è½½è¿™ä¸ªæ•°æ®åº“")
    print(f"\nä½¿ç”¨æ–¹æ³•:")
    print(f"1. åœ¨ index.html ä¸­åŠ è½½ {base64_file}")
    print(f"2. ç”¨æˆ·æ‰“å¼€é¡µé¢å³å¯ç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€å¯¼å…¥")


if __name__ == '__main__':
    main()
