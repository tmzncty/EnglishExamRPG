"""
Exam è·¯ç”± â€” è¯•å·åˆ—è¡¨ã€è¯¦æƒ…ã€å®¢è§‚é¢˜æäº¤
"""
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from typing import List, Dict, Any
import json
import traceback

from app.db.session import get_static_db
from app.db.models import Paper, Question
from app.db.helpers import (
    get_profile_conn, ensure_auto_save,
    get_user_hp, get_user_max_hp, update_user_hp,
)
from contextlib import closing
from app.services.game_mechanics import game_mechanics

router = APIRouter()


@router.get("/exams", response_model=List[Dict[str, Any]])
def get_exams(db: Session = Depends(get_static_db)):
    """è·å–æ‰€æœ‰è¯•å·åˆ—è¡¨"""
    papers = db.query(Paper).order_by(Paper.year.desc()).all()
    return [
        {
            "paper_id": p.paper_id,
            "year": p.year,
            "title": p.title or f"{p.year}å¹´è€ƒç ”è‹±è¯­{p.exam_type}",
            "exam_type": p.exam_type,
        }
        for p in papers
    ]


@router.get("/exam/{paper_id}", response_model=Dict[str, Any])
def get_exam_detail(paper_id: str, db: Session = Depends(get_static_db)):
    """è·å–è¯•å·è¯¦æƒ…ï¼Œèšåˆä¸ºå‰ç«¯å¯ç”¨ç»“æ„"""
    paper = db.query(Paper).filter(Paper.paper_id == paper_id).first()
    if not paper:
        raise HTTPException(status_code=404, detail="Paper not found")

    questions = db.query(Question).filter(Question.paper_id == paper_id).all()

    sections = {
        "use_of_english": None,
        "reading_a": [],
        "reading_b": [],
        "translation": None,
        "writing_a": None,
        "writing_b": None,
    }

    grouped_reading = {}

    # reading_b é»˜è®¤ A-G é€‰é¡¹ (7é€‰5é¢˜å‹)
    READING_B_DEFAULT_OPTIONS = {k: k for k in "ABCDEFG"}

    for q in questions:
        # è§£æé€‰é¡¹ï¼›reading_b å¦‚æœ DB ä¸­æ— é€‰é¡¹åˆ™å…œåº• A-G
        raw_options = json.loads(q.options_json) if q.options_json else None
        if raw_options is None and q.section_type == "reading_b":
            raw_options = READING_B_DEFAULT_OPTIONS

        q_data = {
            "q_id": q.q_id,
            "question_number": q.question_number,
            "content": q.content,
            "options": raw_options,
            "q_type": q.q_type,
            "score": q.score,
        }

        st = q.section_type

        if st == "use_of_english":
            if not sections["use_of_english"]:
                sections["use_of_english"] = {"passage": q.passage_text, "questions": []}
            sections["use_of_english"]["questions"].append(q_data)

        elif st in ["reading_a", "reading_b"]:
            gn = q.group_name or "Text 1"
            if st not in grouped_reading:
                grouped_reading[st] = {}
            if gn not in grouped_reading[st]:
                grouped_reading[st][gn] = {"group_name": gn, "passage": q.passage_text, "questions": []}
            grouped_reading[st][gn]["questions"].append(q_data)

        elif st == "translation":
            if not sections["translation"]:
                sections["translation"] = {"passage": q.passage_text, "questions": []}
            sections["translation"]["questions"].append(q_data)

        elif st in ["writing_a", "writing_b"]:
            if not sections[st]:
                sections[st] = {
                    "q_id": q.q_id,
                    "prompt": q.content,
                    "image":  None,   # æ”¶é½åå¡«å……
                    "passage": q.passage_text,
                    "questions": [],
                }
            # ä¼˜å…ˆæå–å›¾ç‰‡ï¼šåªè¦æ‰¾åˆ°ç¬¬ä¸€å¼ æœ‰æ•ˆå›¾å°±å®šä¸‹
            if not sections[st]["image"] and q.image_base64 and len(q.image_base64) > 100:
                sections[st]["image"] = q.image_base64
            # prompt ä¹Ÿä¼˜å…ˆå–éç©ºçš„
            if not sections[st]["prompt"] and q.content:
                sections[st]["prompt"] = q.content
            # questions åˆ—è¡¨ï¼ˆä¸»è§‚é¢˜å¯èƒ½æœ‰å¤šè¡Œï¼‰
            sections[st]["questions"].append(q_data)

    if sections["use_of_english"]:
        sections["use_of_english"]["questions"].sort(key=lambda x: x["question_number"] or 0)
    if sections["translation"]:
        sections["translation"]["questions"].sort(key=lambda x: x["question_number"] or 0)

    for st in ["reading_a", "reading_b"]:
        if st in grouped_reading:
            groups = list(grouped_reading[st].values())
            for g in groups:
                g["questions"].sort(key=lambda x: x["question_number"] or 0)
            groups.sort(key=lambda g: g["questions"][0]["question_number"] if g["questions"] else 0)
            sections[st] = groups

    return {
        "id": paper.paper_id,
        "title": paper.title,
        "year": paper.year,
        "sections": sections,
    }


@router.post("/exam/submit_objective")
def submit_objective(data: Dict[str, Any], db: Session = Depends(get_static_db)):
    """
    æäº¤å®¢è§‚é¢˜ç­”æ¡ˆã€‚
    - åˆ¤æ–­æ­£è¯¯
    - è®¡ç®—ä¼¤å®³ï¼ˆæŒ‰é¢˜å‹ï¼‰
    - å†™å…¥ femo_profile.db (HP æŒä¹…åŒ–)
    - è¿”å›åˆ¤é¢˜ç»“æœ + æœ€æ–° HP
    """
    q_id     = data.get("q_id")
    user_ans = data.get("answer")

    q = db.query(Question).filter(Question.q_id == q_id).first()
    if not q:
        return {"correct": False, "correct_answer": None, "hp_change": 0, "hp": 100}

    is_correct  = (user_ans == q.correct_answer)
    section_type = q.section_type or "reading_a"

    # â”€â”€ è®¡ç®—é¢˜å‹ä¼¤å®³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if is_correct:
        hp_change = 0
    elif section_type == "use_of_english":
        hp_change = -game_mechanics.damage.use_of_english_damage()  # -2
    else:
        hp_change = -game_mechanics.damage.reading_damage()           # -5

    # â”€â”€ å†™å…¥æ•°æ®åº“ HP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    new_hp = 100  # fallback
    try:
        with get_profile_conn() as pconn:
            ensure_auto_save(pconn)
            current_hp = get_user_hp(pconn)
            max_hp     = get_user_max_hp(pconn)
            new_hp     = max(0, min(max_hp, current_hp + hp_change))
            if hp_change != 0:
                update_user_hp(pconn, new_hp)
    except Exception as e:
        print(f"[exam] HP å†™åº“å¤±è´¥: {e}")

    # â”€â”€ é€šçŸ¥ Mia æƒ…ç»ª â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    mood_info = game_mechanics.get_mia_mood(new_hp, max_hp)

    return {
        "correct":        is_correct,
        "correct_answer": q.correct_answer,
        "hp_change":      hp_change,
        "hp":             new_hp,
        "max_hp":         max_hp,
        "mood":           mood_info["mood"],
    }


@router.post("/exam/submit_subjective")
async def submit_subjective(data: Dict[str, Any]):
    """
    æäº¤ä¸»è§‚é¢˜ï¼ˆç¿»è¯‘ / ä½œæ–‡ï¼‰ã€‚
    - å°è¯•è°ƒç”¨ LLM æ‰¹æ”¹
    - å¤±è´¥åˆ™ Mock è¯„åˆ†
    - æ›´æ–° HP
    """
    q_id         = data.get("q_id", "")
    answer       = data.get("answer", "")
    section_type = data.get("section_type", "translation")

    # â”€â”€ æŒ‰é¢˜å‹å†³å®šæ»¡åˆ†å’Œ HP æ¶ˆè€— â”€â”€
    type_cfg = {
        "translation": {"max_score": 10,  "hp_base": -3},
        "writing_a":   {"max_score": 10,  "hp_base": -4},
        "writing_b":   {"max_score": 20,  "hp_base": -5},
    }
    cfg = type_cfg.get(section_type, {"max_score": 10, "hp_base": -3})
    max_score = cfg["max_score"]

    # â”€â”€ 3. å°è¯• AI æ‰¹æ”¹ (è°ƒç”¨å°è£…å¥½çš„ Robust Service) â”€â”€
    score      = 0.0
    feedback   = ""
    detailed_analysis = ""

    try:
        from app.services.llm_service import llm_service
        
        # å‡†å¤‡ä¸Šä¸‹æ–‡
        context_info = {"section_type": section_type}
        
        # å°è¯•è·å–é¢˜ç›® context (å›¾ã€æ–‡ã€å‚è€ƒç­”æ¡ˆ)
        q_image = None
        standard_ans = "ç•¥"
        
        from app.db.session import StaticSessionLocal
        sdb = StaticSessionLocal()
        try:
            q_obj = sdb.query(Question).filter(Question.q_id == q_id).first()
            if q_obj:
                # è¡¥å…… context_info
                context_info["source_text"] = q_obj.content or q_obj.passage_text or ""
                context_info["topic"] = q_obj.content or ""
                context_info["image_base64"] = q_obj.image_base64  # <--- FIXED: ä¼ é€’å›¾ç‰‡
                standard_ans = q_obj.official_analysis or q_obj.correct_answer or "ç•¥"
        except Exception:
            pass
        finally:
            sdb.close()

        # è°ƒç”¨ Service
        result = await llm_service.grade_subjective_question(
            question_type=section_type,
            user_text=answer,
            standard_answer=standard_ans,
            context_info=context_info
        )
        
        # æå–ç»“æœ
        score = float(result.get("score", 0.0))
        feedback = result.get("feedback") or result.get("mia_comment") or "æœ¬å–µç´¯äº†ï¼Œæš‚æ—¶æ²¡è¯„è¯­å–µã€‚"
        detailed_analysis = str(result.get("detailed_analysis") or result.get("suggestions") or result.get("key_points_missed") or "æš‚æ— è¯¦ç»†åˆ†æã€‚")

    except Exception as e:
        error_trace = traceback.format_exc()
        print(f"\n[ğŸ”¥ FATAL ERROR in submit_subjective]\n{error_trace}\n")
        # é™çº§å¤„ç†ï¼Œä¸å†æŠ›å‡º 500
        score = 0
        feedback = f"è¯„åˆ†ç³»ç»Ÿæš‚æ—¶æ•…éšœ: {str(e)}"
        detailed_analysis = "Error in AI Service."

    # 4. Score Clamping (å¼ºåˆ¶ç†”æ–­)
    final_score = max(0.0, min(score, max_score))
    score = round(final_score, 1)

    # â”€â”€ 5. HP æ›´æ–° â”€â”€
    # æ‰£é™¤å›ºå®š HP (åªè¦æäº¤å°±æ¶ˆè€—ç²¾åŠ›)ï¼Œå¦‚æœä½åˆ†é¢å¤–æƒ©ç½šï¼Ÿæš‚åªæ‰£åŸºç¡€
    hp_change = cfg["hp_base"]
    new_hp    = 100
    max_hp    = 100
    try:
        with get_profile_conn() as pconn:
            ensure_auto_save(pconn)
            current_hp = get_user_hp(pconn)
            max_hp     = get_user_max_hp(pconn)
            new_hp     = max(0, min(max_hp, current_hp + hp_change)) # å…è®¸æ‰£ä¸º0
            update_user_hp(pconn, new_hp)
    except Exception as e:
        print(f"[exam] subjective HP å†™åº“å¤±è´¥: {e}")

    return {
        "score":        score,
        "max_score":    max_score,
        "mia_feedback": feedback,
        "detailed_analysis": detailed_analysis,
        "hp_change":    hp_change,
        "hp":           new_hp,
        "max_hp":       max_hp,
    }
